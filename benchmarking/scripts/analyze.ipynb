{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze e2e latencies for the single_client_e2e experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def get_results(path):\n",
    "    computee2e, confirme2e = [], []\n",
    "    consumee2e = []\n",
    "    avg_batching_latencies = []\n",
    "    avg_batch_size = []\n",
    "    runtime = 0\n",
    "    total_append_per_client = []\n",
    "    with open(path+\"/client_node7.log\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"latencies: \" in line:\n",
    "                consume, confirm, compute = line.strip().split('latencies: ')[-1].split(',')[-3:]\n",
    "                consumee2e.append(int(consume))\n",
    "                confirme2e.append(int(confirm))\n",
    "                computee2e.append(int(compute))\n",
    "            if \"average batch size: \" in line:\n",
    "                avg_batch_size.append(float(line.strip().split()[-1]))\n",
    "            if \"average batching latency: \" in line:\n",
    "                avg_batching_latencies.append(float(line.strip().split()[-1]))\n",
    "            if \"avg latency of\" in line:\n",
    "                total_append_per_client.append(float(line.split('[single_client_e2e]:')[1].split()[3]))\n",
    "            if \"starting benchmark with runtime\" in line:\n",
    "                runtime = float(line.strip().split()[-1])\n",
    "\n",
    "    computee2e = np.array(computee2e, dtype=int)\n",
    "    confirme2e = np.array(confirme2e, dtype=int)\n",
    "    consumee2e = np.array(consumee2e, dtype=int)\n",
    "\n",
    "    temp = np.maximum(computee2e, confirme2e)\n",
    "\n",
    "    print(\"results for computation time \" + path.split(\"_\")[-1] + \" us\")\n",
    "    print(\"statistic/metric, compute e2e (us), confirm e2e (us), consume e2e (us), total e2e (us)\")\n",
    "    print(f\"mean, {np.mean(computee2e):.2f}, {np.mean(confirme2e):.2f}, {np.mean(consumee2e):.2f}, {np.mean(temp):.2f}\")\n",
    "    print(f\"std, {np.std(computee2e):.2f}, {np.std(confirme2e):.2f}, {np.std(consumee2e):.2f}, {np.std(temp):.2f}\")\n",
    "    print(f\"p50, {np.percentile(computee2e, 50):.2f}, {np.percentile(confirme2e, 50):.2f}, {np.percentile(consumee2e, 50):.2f}, {np.percentile(temp, 50):.2f}\")\n",
    "    print(f\"p99, {np.percentile(computee2e, 90):.2f}, {np.percentile(confirme2e, 90):.2f}, {np.percentile(consumee2e, 90):.2f}, {np.percentile(temp, 90):.2f}\")\n",
    "\n",
    "    print(\"average batch size, average batching latencies, avg throughput\")\n",
    "    print(f\"{avg_batch_size[-1]:.2f}, {avg_batching_latencies[-1]:.2f}, {np.sum(total_append_per_client)/runtime:.2f}\")\n",
    "\n",
    "    return np.mean(computee2e), np.mean(confirme2e), np.mean(consumee2e), np.mean(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "compute = []\n",
    "confirm = []\n",
    "consume = []\n",
    "total = []\n",
    "\n",
    "# comp_times=[\"100\", \"200\", \"500\", \"800\", \"1000\", \"1200\"]\n",
    "comp_times=[\"100\"]\n",
    "for comp_time in comp_times:\n",
    "    compute_lat, confirm_lat, consume_lat, total_lat = get_results(f\"../results/logs/e2e_{comp_time}\")\n",
    "    compute.append(compute_lat)\n",
    "    confirm.append(confirm_lat)\n",
    "    consume.append(consume_lat)\n",
    "    total.append(total_lat)\n",
    "    print(\"****************************\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(comp_times, confirm, label='confirm', marker='x')\n",
    "ax.plot(comp_times, consume, label='consume', marker='x')\n",
    "ax.plot(comp_times, total, label='total', marker='x')\n",
    "\n",
    "ax.set(xlabel='computation time (us)', ylabel='latency (us)', title='latency vs computation time')\n",
    "ax.set_ylim(ymin=0)\n",
    "ax.set_xlim(xmin=0)\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "fig.savefig(\"latency_vs_comp_time.png\", dpi=600)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
